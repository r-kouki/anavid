---
title: "Student Employability Prediction"
subtitle: "Machine Learning Classification Model"
author: "Computer Science Student"
format:
  revealjs:
    theme: [default, custom.scss]
    slide-number: true
    chalkboard: true
    preview-links: auto
    logo: ""
    css: styles.css
    footer: "Employability ML Project | 2026"
jupyter: python3
---

## ğŸ“Š Project Overview {.smaller}

**Goal:** Predict student employability using machine learning

**What we built:**

- ğŸ¤– Random Forest classification model
- ğŸ“ˆ 92% accuracy on real student data
- ğŸŒ Interactive web app for predictions
- ğŸ“Š Comprehensive data analysis

**Why it matters:** Help universities and students identify factors that improve job prospects

::: {.notes}
This project demonstrates practical machine learning application in education sector. We're using real data from 260 students to predict employability outcomes.
:::

---

## ğŸ“ The Data {.smaller}

```{python}
#| echo: true
#| code-fold: false
import pandas as pd
import matplotlib.pyplot as plt

# Load the dataset
df = pd.read_excel("data.xlsx", engine='openpyxl')

print(f"Dataset size: {df.shape[0]} students, {df.shape[1]} features")
print(f"\nColumns: {list(df.columns[:10])} ...")
```

**Key Features:**

::: {.columns}
::: {.column width="50%"}
- ğŸ“š Demographics (Gender, Nationality, Major)
- ğŸ¯ Skill Assessments (Innovation, Soft Skills)
- ğŸ”¬ Research & Analytical Skills
:::

::: {.column width="50%"}
- ğŸ’¼ Professional Development Scores
- ğŸ­ Industry Metrics
- ğŸ’» Work Experience
:::
:::

---

## âš–ï¸ Balanced Classes {.smaller}

```{python}
#| echo: true
#| fig-align: center
#| fig-width: 8
#| fig-height: 5

# Check class distribution
class_dist = df['Class'].value_counts()
print(f"Class 0 (Not Highly Employable): {class_dist[0]} students")
print(f"Class 1 (Highly Employable): {class_dist[1]} students")

# Visualize
fig, ax = plt.subplots(figsize=(7, 4))
colors = ['#ff6b6b', '#51cf66']
bars = ax.bar(['Class 0\n(Not Employable)', 'Class 1\n(Employable)'], 
              class_dist.values, color=colors, edgecolor='black', linewidth=2)

# Add value labels
for bar in bars:
    height = bar.get_height()
    ax.text(bar.get_x() + bar.get_width()/2., height,
            f'{int(height)} students\n({height/len(df)*100:.1f}%)',
            ha='center', va='bottom', fontweight='bold', fontsize=12)

ax.set_ylabel('Number of Students', fontsize=12)
ax.set_title('Almost Perfectly Balanced Dataset', fontsize=14, fontweight='bold')
plt.tight_layout()
plt.show()
```

**Why this matters:** Balanced data = fair predictions for both classes âœ…

---

## ğŸ”§ Data Preprocessing {.smaller}

```{python}
#| echo: true
#| output: true

from sklearn.impute import SimpleImputer

# Remove ID column (not predictive)
df_clean = df.drop('ID', axis=1)

# Separate features and target
X = df_clean.drop('Class', axis=1)
y = df_clean['Class']

# Handle missing values
imputer = SimpleImputer(strategy='mean')
X_imputed = imputer.fit_transform(X)

print(f"âœ“ Removed non-predictive ID column")
print(f"âœ“ Features: {X.shape[1]} columns")
print(f"âœ“ Missing values handled: {df.isnull().sum().sum()} filled with column means")
```

**Simple explanation:** We clean the data by removing student IDs (which don't help prediction) and fill in any missing values with average scores.

::: {.notes}
For non-technical: Think of this like preparing ingredients before cooking - we remove what we don't need and fill in gaps.
:::

---

## ğŸŒ² The Model: Random Forest {.smaller}

```{python}
#| echo: true
#| output: true

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split

# Split data: 80% training, 20% testing
X_train, X_test, y_train, y_test = train_test_split(
    X_imputed, y, test_size=0.2, random_state=42, stratify=y
)

# Create and train the model
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

print(f"âœ“ Model trained with {model.n_estimators} decision trees")
print(f"âœ“ Training samples: {len(X_train)}")
print(f"âœ“ Test samples: {len(X_test)}")
```

**Technical:** Ensemble of 100 decision trees with majority voting

**Non-technical:** Imagine 100 experts each making a prediction, then we take the majority vote. This reduces errors! ğŸ—³ï¸

---

## ğŸ“Š Model Performance {.smaller}

```{python}
#| echo: true
#| fig-align: center
#| fig-width: 10
#| fig-height: 4

from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns

# Make predictions
y_pred = model.predict(X_test)

# Print metrics
print("Performance Metrics:")
print(classification_report(y_test, y_pred))

# Visualize confusion matrix
fig, ax = plt.subplots(figsize=(6, 4))
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,
            xticklabels=['Not Employable', 'Employable'],
            yticklabels=['Not Employable', 'Employable'])
ax.set_xlabel('Predicted', fontsize=12)
ax.set_ylabel('Actual', fontsize=12)
ax.set_title('Confusion Matrix - Where the Model Makes Mistakes', fontsize=13, fontweight='bold')
plt.tight_layout()
plt.show()
```

**Result:** 92% accuracy! ğŸ¯

---

## ğŸ” Feature Importance {.smaller}

```{python}
#| echo: true
#| fig-align: center
#| fig-width: 10
#| fig-height: 5

# Get feature importance
feature_importance = pd.DataFrame({
    'feature': X.columns,
    'importance': model.feature_importances_
}).sort_values('importance', ascending=False)

print("Top 5 Most Important Features:")
print(feature_importance.head())

# Visualize top 10
top_10 = feature_importance.head(10)
fig, ax = plt.subplots(figsize=(10, 5))
bars = ax.barh(top_10['feature'], top_10['importance'], color='#4dabf7', edgecolor='black')
ax.set_xlabel('Importance Score', fontsize=12)
ax.set_title('Top 10 Features That Matter Most', fontsize=14, fontweight='bold')
ax.invert_yaxis()
plt.tight_layout()
plt.show()
```

**Insight:** The model focuses most on certain skills and metrics to make predictions.

---

## ğŸ’» Our Code Choices {.smaller}

**Why Random Forest?**

::: {.incremental}
- âœ… Handles non-linear relationships well
- âœ… Robust to outliers and noise
- âœ… Provides feature importance automatically
- âœ… No need for feature scaling
- âœ… Works great with small datasets (260 samples)
:::

**Why StratifiedKFold Cross-Validation?**

::: {.incremental}
- âœ… Maintains class balance in each fold
- âœ… More reliable performance estimates
- âœ… Prevents overfitting on small datasets
:::

**Technical note:** We used `n_estimators=100` and `random_state=42` for reproducibility.

---

## ğŸ¯ Why Our Approach Works {.smaller}

**For Technical Audience:**

- Used **mean imputation** (sklearn-native, preserves distribution)
- **80/20 stratified split** maintains 51/49 class ratio
- **5-fold CV** with F1 scoring (balanced precision/recall)
- **F1 Score: 0.97 Â± 0.06** shows consistent performance

**For Non-Technical Audience:**

Think of our model like a smart filter:

1. ğŸ“¥ We feed it student data (skills, grades, experience)
2. ğŸ§  It learns patterns from 208 students
3. âœ… We test on 52 new students it hasn't seen
4. ğŸ¯ It correctly predicts 92 out of 100 cases!

---

## ğŸŒ Deployment: Web App {.smaller}

**Built with Streamlit** - Interactive Python web framework

**Two ways to use:**

::: {.columns}
::: {.column width="50%"}
**1ï¸âƒ£ Manual Entry**
- Enter values one by one
- Load example data
- Instant prediction
- See confidence scores
:::

::: {.column width="50%"}
**2ï¸âƒ£ Excel Upload**
- Upload .xlsx file
- Batch predictions
- Download results as CSV
- Visual analytics
:::
:::

**Live Demo:** [Your Streamlit Cloud URL]

::: {.callout-tip}
## Try It Yourself!
Upload your own student data or use manual entry to see predictions in real-time.
:::

---

## ğŸ“ˆ Business Value {.smaller}

**For Universities:**

- ğŸ“ Identify students who need more support
- ğŸ“Š Track program effectiveness
- ğŸ’¡ Focus resources on impactful interventions

**For Students:**

- ğŸ¯ Understand strengths and weaknesses
- ğŸ“ Get personalized improvement suggestions
- ğŸ’¼ Better prepare for job market

**For Employers:**

- ğŸ” Data-driven candidate screening
- âš¡ Faster recruitment decisions
- ğŸ¯ Better skill-to-role matching

---

## ğŸš€ Deployment Pipeline {.smaller}

```mermaid
graph LR
    A[Train Model] --> B[Save Artifacts]
    B --> C[Build Streamlit App]
    C --> D[Deploy to Cloud]
    B --> E[Create Analysis]
    E --> F[GitHub Pages]
    style A fill:#ffb3ba
    style C fill:#bae1ff
    style E fill:#baffc9
```

**Our Stack:**

- ğŸ **Python** - Core language
- ğŸ¤– **scikit-learn** - Machine learning
- ğŸˆ **Streamlit** - Web interface
- ğŸ“Š **Quarto** - Documentation & slides
- ğŸ”§ **GitHub** - Version control & hosting

---

## ğŸ“š Key Takeaways {.smaller}

::: {.incremental}
1. **Balanced data is crucial** - Our 51/49 split ensures fair predictions
2. **Random Forest is reliable** - 92% accuracy with interpretable results
3. **Preprocessing matters** - Handling missing values properly improves performance
4. **Cross-validation prevents overfitting** - 5-fold CV gives reliable estimates
5. **Deployment makes impact** - Interactive app makes ML accessible to everyone
:::

::: {.callout-important}
## Real-World Application
This isn't just a class project - it's a production-ready system that can help real students and universities make better decisions.
:::

---

## ğŸ”® Future Improvements {.smaller}

**Potential Enhancements:**

- ğŸ“Š Add more features (internships, certifications, projects)
- ğŸ§  Try deep learning models (neural networks)
- ğŸ“ˆ Real-time data updates and retraining
- ğŸŒ Multi-region support with different job markets
- ğŸ“± Mobile app version
- ğŸ’¬ Add explanation system (SHAP values)

**Research Questions:**

- Which specific skills most impact employability?
- How do trends change over time?
- Can we predict salary ranges too?

---

## ğŸ™ Thank You! {.center}

::: {.r-fit-text}
**Questions?**
:::

**Project Links:**

- ğŸŒ [Live App - Streamlit Cloud](#)
- ğŸ“Š [GitHub Repository](#)
- ğŸ“„ [Full Documentation](#)
- ğŸ“§ [Contact](#)

::: {.callout-note}
## Resources
All code, data, and documentation available on GitHub. Feel free to fork and improve!
:::

---

## ğŸ“– Appendix: Technical Details {.smaller visibility="uncounted"}

**Model Hyperparameters:**

```python
RandomForestClassifier(
    n_estimators=100,      # Number of trees
    random_state=42,        # Reproducibility
    max_features='sqrt',    # Feature sampling
    min_samples_split=2,    # Minimum split size
    min_samples_leaf=1      # Minimum leaf size
)
```

**Cross-Validation Results:**

- Fold 1: F1 = 0.9412
- Fold 2: F1 = 0.9200
- Fold 3: F1 = 1.0000
- Fold 4: F1 = 1.0000
- Fold 5: F1 = 0.9804
- **Mean: 0.9683 Â± 0.0647**
